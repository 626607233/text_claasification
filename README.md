# text_claasification
A Repository for one of NLP tasks---text classification, with different implementations.
## Requirements
- Python 3
- Tensorflow 1.11
## Methods
1. CNN 
- papaer: Convolutional Neural Networks for Sentence Classification
- blog: [【NLP保姆级教程】手把手带你CNN文本分类(附代码)](https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&mid=100000370&idx=1&sn=7448bbc1060f70a9098b74fe7698e6af&chksm=17aee4a020d96db667da15dc643bd1a1c30c26f9fb98087e5479d8efadb0a97338080d499317#rd)
2. RNN
- paper: Recurrent Neural Network for Text Classification with Multi-Task Learning
- blog: [【NLP保姆级教程】手把手带你RNN文本分类(附代码)](http://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&mid=100000391&idx=1&sn=f787b51049d3c40e97fce8cc2c24fd00&chksm=17aee45520d96d4388def1cc250954d5b2fd3820a2ebccbc9f8457de5fafe723d2e70b55dc56#rd)
3. fastText
- paper: Bag of Tricks for Efficient Text Classification
- blog: [【NLP保姆级教程】手把手带你fastText文本分类(附代码)](http://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&mid=100000424&idx=2&sn=c1c142753843dcbe32fb820866c3c6f5&chksm=17aee47a20d96d6cd1330bb1681ec22bc88ef415f6f70af866d2258facf276034493e2409b2a#rd)
4. RCNN
- paper: Recurrent Convolutional Neural Networks for Text Classification
- blog: [【NLP保姆级教程】手把手带你RCNN文本分类(附代码)](http://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&mid=100000605&idx=3&sn=13c3300a9a1bd1d8b2288341bcfc54ac&chksm=17aee58f20d96c991042595507ff17f11976c52f698f44de2364d54660b244a88591f4bb7dbd#rd)
5. HAN
- paper: Hierarchical Attention Networks for Document Classification
- blog:  [【NLP保姆级教程】手把手带你HAN文本分类(附代码)](http://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&mid=100000605&idx=1&sn=12e19e0a833bca6d6e384561fc8a0da9&chksm=17aee58f20d96c99b20f565eda28c862039c2dc8f9c9890f0767afdb92b8c51c6386462cb8a0#rd)
6. CHAR-CNN
- paper: Character-level Convolutional Networks for Text Classification
- blog:  [【NLP保姆级教程】手把手带你CHAR-CNN文本分类(附代码)](http://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&mid=100000424&idx=2&sn=c1c142753843dcbe32fb820866c3c6f5&chksm=17aee47a20d96d6cd1330bb1681ec22bc88ef415f6f70af866d2258facf276034493e2409b2a#rd) 
7. BERT  
- paper: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding  
- repository: https://github.com/google-research/bert  
- blog: 

